server:
  port: 8080
spring:
  data:
    elasticsearch:
      cluster-name: elasticsearch #默认即为 elasticsearch
      cluster-nodes: 172.18.9.188:9300 #配置es节点信息，逗号分隔，如果没有指定，则启动ClientNode
#      elasticsearch.yml 配置
#      network.host: 172.18.9.188
#      transport.tcp.port: 9300
    mongodb:
      uri: mongodb://localhost:27017/test
  redis:
    #数据库索引
    database: 0
    host: 127.0.0.1
    port: 6379
    password:
    jedis:
      pool:
        #最大连接数
        max-active: 8
        #最大阻塞等待时间(负数表示没限制)
        max-wait: -1
        #最大空闲
        max-idle: 8
        #最小空闲
        min-idle: 0
      #连接超时时间
      timeout: 10000
  jpa:
   database: mysql
   hibernate:
      ddl-auto: update
   show-sql: true
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf-8&useSSL=true&serverTimezone=UTC
    username: root
    password: root
#  rabbitmq:
#    addresses: amqp://127.0.0.1:5672
#    username: michael
#    password: michael

#  jpa:
#    database: h2
#    hibernate:
#      ddl-auto: create
#    show-sql: true
#  datasource:
#    driver-class-name: org.h2.Driver
#    #url有以下几种形式:
#    # jdbc:h2:E:*/database 会持久化到磁盘文件，但是是单连接
#    # jdbc:h2:tcp://IP/database 通过远程连接的方式
#    # jdbc:h2:mem:database 直接在内存中，程序只要重启就会消失
#    url: jdbc:h2:mem:h2test
#    username: sa
#    password:
##    程序启动后会初始化这些脚本文件
##    schema: classpath:db/schema.sql
##    data: classpath:db/data.sql
#  h2:
#    console:
#      settings:
#        web-allow-others: true
#      path: /h2-console
#      enabled: true

  kafka:
    bootstrap-servers: 127.0.0.1:9092
    consumer:
      bootstrap-servers: 127.0.0.1:9092
      ### 指定默认消费者group id
      group-id: springboot-kafka
      ### 当Kafka中没有初始偏移量或者服务器上不再存在当前偏移量时该怎么办，默认值为latest，表示自动将偏移重置为最新的偏移量,可选的值为latest, earliest, none
      auto-offset-reset: latest
      ### 如果为true，则消费者的偏移量将在后台定期提交，默认值为true
      enable-auto-commit: true
      ### 如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000
      auto-commit-interval: 2000
      fetch-max-wait: 4000
      max-poll-records: 50
      ### 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      bootstrap-servers: 127.0.0.1:9092
      ### 如果该值大于零时，表示启用重试失败的发送次数
      retries: 0
      ### 每次批量发送消息的数量
      batch-size: 4096
      buffer-memory: 40960
      linger: 1
      ### 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    listener:
      concurrency: 1
    topics:
      test: nginx_log
mybatis:
  type-aliases-package: com.example.demo.mybatis.domain
  mapperLocations: classpath:mapper/*.xml
